{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH5 Deep Learning For Computer Vision\n",
    "\n",
    "* Convolutional neural networks, also known as convnets, a type of deep-learning model almost universally used in computer vision applications.\n",
    "  \n",
    "* Importantly, a convnet takes as input tensors of shape (image_height, image_width, image_channels) (not including the batch dimension). In this case, we’ll configure the convnet to process inputs of size (28, 28, 1).\n",
    "  \n",
    "* The output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels).\n",
    "  \n",
    "* The width and height dimensions tend to shrink as you go deeper in the network. The number of channels is controlled by the first argument passed to the Conv2D layers (32 or 64).\n",
    "\n",
    "## Necessary Background \n",
    "  \n",
    "* Tensor is a container for numerical data. It is the way we store the information that we will use within our system.\n",
    "  * Three Attributes\n",
    "    * 1. Rank - refers to the tensor's number of axes\n",
    "    * 2. Shape - refers to the number of dimensions along each axis \n",
    "    * 3. Data Type - refers to the type of data that is housed in the container\n",
    "\n",
    "* Vector vs a Tensor\n",
    "  * Vector only has one axis, thus it has a rank of one. While a Matrix has two axis, so it is a rank two. \n",
    "\n",
    "* Shape\n",
    "  * A Square Matrix may have (2,2) dimensions \n",
    "  * A Tensor of RANK 3 may have (3,5,8) dimension. A Vector is a 1-RANK or 1-axis TENSOR but it can have 3 dimensions. \n",
    "    * [3,5,8] vs [[3,5,8]] vs [[[3,5,8]]] : 1AXIS|1RANK|3DIMENSIONS ; 2AXIS|2RANK|3DIMENSIONS ; 3AXIS|3RANK|3DIMENSIONS\n",
    "\n",
    "* Supported Data Types\n",
    "  * float32, float64\n",
    "  * uint8\n",
    "  * int32\n",
    "  * int64\n",
    "\n",
    "* A ZERO DIMENSIONAL TENSOR OR a SCALAR \n",
    "  * Contains only a single number \n",
    "  * 12 is a zero dimensional tensor; thus it has no brackets \n",
    "\n",
    "* <code> tensor_scalar = np.array(42)<br>\n",
    "  tensor_scaler.shape # () <br>\n",
    "  tensor.ndim # rank = ndim 0</code>\n",
    "\n",
    "* <code> tensor_vector = np.array([42,24,16,8])<br>\n",
    "  tensor_scaler.shape # (4,) <br>\n",
    "  tensor.ndim # rank = ndim 1</code>\n",
    "\n",
    "* <code> tensor_matrix = np.array([[42,24,24],[42,24,24]])<br>\n",
    "  tensor_scaler.shape # (3,2) <br>\n",
    "  tensor.ndim # rank = ndim 2</code>\n",
    "\n",
    "* Vectors: 1D — (features)\n",
    "\n",
    "* Sequences: 2D — (timesteps, features)\n",
    "\n",
    "* Images: 3D — (height, width, channels)\n",
    "\n",
    "* Videos: 4D — (frames, height, width, channels)\n",
    "\n",
    "* Machine learning algorithms deal with a subset of data at a time called batches.\n",
    "\n",
    "* When using a batch of data, the tensor’s first axis is reserved for the size of the batch (number of samples.)\n",
    "\n",
    "* For example, if your handling 2D tensors (matrices), a batch of them will have a total of 3 dimensions: White small square (samples, rows, columns)\n",
    "\n",
    "## Back to Introduction to <emphasis><bold>Convnets</bold></emphasis> & <emphasis><bold>Convnets</bold></emphasis>\n",
    "\n",
    "### The Convolution Operation\n",
    "* Dense layers learn global patterns in their input feature space\n",
    "\n",
    "* Convolution layers learn local patterns\n",
    "\n",
    "* Convnets have two interesting properties then:\n",
    "  * The patterns they learn are translation invariant. \n",
    "    * After learning a certain pattern in the lower-right corner of a picture, a convnet can recognize it anywhere\n",
    "  * They can learn spatial hiierarchies of patterns. \n",
    "    * A first convolution layer will learn small local patterns such as edges, a second convolution layer will learn larger patterns made of the features of the first layers, and so on.\n",
    "\n",
    "* Convolutions operate over 3D tensors, called feature maps, with two spatial axes (height and width) as well as a depth axis (also called the channels axis)\n",
    "\n",
    "* Convolutions are defined by two key parameters:\n",
    "  * Size of the patches extracted from the inputs—These are typically 3 × 3 or 5 × 5. \n",
    "  * Depth of the output feature map—The number of filters computed by the convolution. The example started with a depth of 32 and ended with a depth of 64\n",
    "\n",
    "* In Keras Conv2D layers, these parameters are the first arguments passed to the layer: Conv2D(output_depth, (window_height, window_width)).\n",
    "\n",
    "* A convolution works by sliding these windows of size 3 × 3 or 5 × 5 over the 3D input feature map, stopping at every possible location, and extracting the 3D patch of surrounding features (shape (window_height, window_width, input_depth)).\n",
    "\n",
    "* ![Convulation_Process](./5.4.PNG)\n",
    "\n",
    "* If you want to get an output feature map with the same spatial dimensions as the input, you can use padding. Padding consists of adding an appropriate number of rows and columns on each side of the input feature map so as to make it possible to fit center convolution windows around every input tile. For a 3 × 3 window, you add one column on the right, one colum,n on the left, one row at the top, and one row at the bottoom.\n",
    "\n",
    "* In Conv2D layers, padding is configurable via the padding argument, which takes two values: \"valid\", which means no padding (only valid window locations will be used);and \"same\", which means “pad in such a way as to have an output with the same width and height as the input.” The padding argument defaults to \"valid\". \n",
    "\n",
    "* The other factor that can influence output size is the notion of strides. The description of convolution so far has assumed that the center tiles of the convolution windows are all contiguous. But the distance between two successive windows is a parameter of the convolution, called its stride.\n",
    "\n",
    "## Max-Pooling Operation \n",
    "\n",
    "* That’s the role of max pooling: to aggressively downsample feature maps, much like strided convolutions.\n",
    "\n",
    "* For instance, before the first MaxPooling2D layers, the feature map is 26 × 26, but the max-pooling operation halves it to 13 × 13.\n",
    "  \n",
    "* Max pooling consists of extracting windows from the input feature maps and outputting the max value of each channel. It’s conceptually similar to convolution, except that instead of transforming local patches via a learned linear transformation (the convolution kernel),they’re transformed via a hardcoded max tensor operation\n",
    "\n",
    "* Because convnets learn local, translation-invariant features, they’re highly data efficient on perceptual problems. Training a convnet from scratch on a very small image dataset will still yield reasonable results despite a relative lack of data, without the need for any custom feature engineering\n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "* \n",
    "\n",
    "*\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpyNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\jzy50\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading numpy-1.22.3-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "     --------------------------------------- 14.7/14.7 MB 65.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.22.3\n"
     ]
    }
   ],
   "source": [
    "pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "tensor_matrix = np.array([[42,24,24],\n",
    "                          [42,24,24]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 4, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_dimensional_tensor = np.array([[[[1,1,1,1],\n",
    "                                      [1,1,1,1],\n",
    "                                      [1,1,1,1],\n",
    "                                      [1,1,1,1]]]])\n",
    "four_dimensional_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_dimensional_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "114035fcc968ac6e5d09e10828f37dfcb6d30913d91b0894dccfae7afa2366bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
